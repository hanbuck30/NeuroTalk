{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_path = \"/home/bxai1/BXAI/Project/NeuroTalk-decoder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_number = \"sub001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp_path = foundation_path + f\"CSP/{sub_number}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "# Load the .mat file\n",
    "data = loadmat(csp_path + 'epoch_data.mat')\n",
    "mat_key = 'fv_te_imagined', 'fv_te_spoken', 'fv_tr_imagined', 'fv_tr_spoken', 'fv_val_imagined', 'fv_val_spoken'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 234)\n"
     ]
    }
   ],
   "source": [
    "print(data['fv_tr_imagined'][0][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_te_imagined = data[mat_key[0]]\n",
    "fv_te_spoken = data[mat_key[1]]\n",
    "fv_tr_imagined = data[mat_key[2]]\n",
    "fv_tr_spoken = data[mat_key[3]]\n",
    "fv_val_imagined = data[mat_key[4]]\n",
    "fv_val_spoken = data[mat_key[5]]\n",
    "all_fv = [fv_te_imagined, fv_te_spoken, fv_tr_imagined, fv_tr_spoken, fv_val_imagined, fv_val_spoken]\n",
    "all_fv_name = [\"fv_te_imagined\", \"fv_te_spoken\", \"fv_tr_imagined\", \"fv_tr_spoken\", \"fv_val_imagined\", \"fv_val_spoken\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is a code that checks if any of the values from running vector_embedding.m have an inf value, and if there is an inf, you can check which trials have shown up. \n",
    "all_fv_ind = 5 # mat_key's length is 5.\n",
    "for i in range(all_fv[all_fv_ind][0][0][0].shape[2]):\n",
    "    if np.isinf(all_fv[all_fv_ind][0][0][0][:,:,i]).any():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In all_fv_name, since train accounts for 60% of the total dataset, it is possible to know where the train file is located in the list of all_fv_name.\n",
    "train_indices = []\n",
    "for i in range(len(all_fv_name)):\n",
    "    if all_fv_name[i].find(\"tr\") != -1:\n",
    "        train_indices.append(i)\n",
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "n_trial_per_classes_in_time = 0 # \n",
    "n_trial_per_classes_in_test = 0 #\n",
    "\n",
    "\n",
    "for j in range(len(all_fv)):\n",
    "    # Checking folder directions\n",
    "    if os.path.isdir(csp_path+all_fv_name[j]):\n",
    "        pass\n",
    "    else: \n",
    "        os.mkdir(csp_path+all_fv_name[j])\n",
    "    if os.path.isdir(csp_path+all_fv_name[j]+'/EEG') and os.path.isdir(csp_path+all_fv_name[j]+'/label'):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(csp_path+all_fv_name[j]+'/EEG')\n",
    "        os.mkdir(csp_path+all_fv_name[j]+'/label')        \n",
    "\n",
    "             \n",
    "\n",
    "    labe = []\n",
    "    # Checking how many labels in list\n",
    "    for i in range(all_fv[j][0][0][1].shape[1]):\n",
    "        # Convert numpy to int like using np[0] and append indicies to list\n",
    "        labe.append(np.where(all_fv[j][0][0][1][:,i] == 1)[0][0])\n",
    "    labe_np = np.array(labe)\n",
    "\n",
    "    for classes in range(13):\n",
    "        # Since the number of trials per class is different, you must specify the time of training, value, and test separately.\n",
    "        if j in train_indices:\n",
    "            n_tr_indices = all_fv[j][0][0][0][:,:,np.where(labe_np==classes)[0]].shape[2]\n",
    "        elif j not in train_indices:\n",
    "            n_te_indices = all_fv[j][0][0][0][:,:,np.where(labe_np==classes)[0]].shape[2]\n",
    "            \n",
    "        # globals()[\"{}_CSP_{}_{}\".format(all_fv_name[j], classes, cnt)] = np.zeros((16,104))\n",
    "        # Need to Checking -inf. So You have to use np.inf to remove the correspond label     \n",
    "        for n in range(all_fv[j][0][0][0][:,:,np.where(labe_np==classes)[0]].shape[2]):\n",
    "            globals()[\"{}_CSP_{}_{}\".format(all_fv_name[j], classes, n)] = np.zeros((16,104))\n",
    "            globals()[\"{}_label_{}_{}\".format(all_fv_name[j], classes, n)] = np.array([0]*13)\n",
    "            if not np.isinf(all_fv[j][0][0][0][:,:,np.where(labe_np==classes)[0][n]]).any():\n",
    "                globals()[\"{}_CSP_{}_{}\".format(all_fv_name[j], classes, n)] = all_fv[j][0][0][0][:,:,np.where(labe_np==classes)[0][n]]\n",
    "                \n",
    "                globals()[\"{}_label_{}_{}\".format(all_fv_name[j], classes, n)][classes] = 1\n",
    "\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_class = 13  # Number of classes\n",
    "\n",
    "for i in range(len(all_fv_name)):\n",
    "    # Since the number of trials per class is different, you must specify the time of training, value, and test separately.\n",
    "    if i in train_indices:\n",
    "        n_indices = n_tr_indices\n",
    "    elif i not in train_indices:\n",
    "        n_indices = n_te_indices\n",
    "\n",
    "    for classes in range(num_class):\n",
    "        for n in range(n_indices):\n",
    "            # If error processing occurs, the file is excluded because there is a nan value or an inf value as a result of CSP.\n",
    "            try:\n",
    "                csp_var_name = f\"{all_fv_name[i]}_CSP_{classes}_{n}\"\n",
    "                label_var_name = f\"{all_fv_name[i]}_label_{classes}_{n}\"\n",
    "                df_CSP= pd.DataFrame(globals()[\"{}_CSP_{}_{}\".format(all_fv_name[i], classes, n)]).T\n",
    "                df_CSP_label = pd.DataFrame(globals()[\"{}_label_{}_{}\".format(all_fv_name[i], classes, n)]).T\n",
    "                # The characteristic of the trainloader is to load files in the order of the names of the files. Therefore, when setting names, it is possible to set them in the desired order.\n",
    "                if classes <= 8:\n",
    "                    if n < 10:\n",
    "                        df_CSP.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"EEG/\" + all_fv_name[i] + \"_\"+ \"00\" + str(classes + 1) + \"_00\"+ f\"{n}\"+ \".csv\", index=False, header=False)\n",
    "                        df_CSP_label.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"label/\" + all_fv_name[i] + \"_\"+ \"00\" + str(classes + 1) +\"_00\"+ f\"{n}\" +\".csv\", index=False, header=False)\n",
    "                    else:\n",
    "                        df_CSP.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"EEG/\" + all_fv_name[i] + \"_\"+ \"00\" + str(classes + 1) + \"_0\"+ f\"{n}\"+ \".csv\", index=False, header=False)\n",
    "                        df_CSP_label.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"label/\" + all_fv_name[i] + \"_\"+ \"00\" + str(classes + 1) +\"_0\"+ f\"{n}\" +\".csv\", index=False, header=False)                        \n",
    "                else:\n",
    "                    if n < 10:\n",
    "                        df_CSP.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"EEG/\" + all_fv_name[i] + \"_\"+ \"0\" + str(classes + 1) +\"_00\"+ f\"{n}\"+\".csv\", index=False, header=False)  \n",
    "                        df_CSP_label.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"label/\" + all_fv_name[i] + \"_\"+ \"0\" + str(classes + 1) +\"_00\"+f\"{n}\"+\".csv\", index=False, header=False) \n",
    "                    else:\n",
    "                        df_CSP.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"EEG/\" + all_fv_name[i] + \"_\"+ \"0\" + str(classes + 1) +\"_0\"+ f\"{n}\"+\".csv\", index=False, header=False)  \n",
    "                        df_CSP_label.to_csv(csp_path + all_fv_name[i]+\"/\"+ \"label/\" + all_fv_name[i] + \"_\"+ \"0\" + str(classes + 1) +\"_0\"+f\"{n}\"+\".csv\", index=False, header=False)                         \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {csp_var_name} or {label_var_name}: {e}\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fv_te_imagined',\n",
       " 'fv_te_spoken',\n",
       " 'fv_tr_imagined',\n",
       " 'fv_tr_spoken',\n",
       " 'fv_val_imagined',\n",
       " 'fv_val_spoken']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_list = os.listdir(csp_path)[:]\n",
    "folder_list.sort()\n",
    "folder_list[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fv_tr_spoken_005_006.csv\n"
     ]
    }
   ],
   "source": [
    "zero_EEG = []\n",
    "folder_list = os.listdir(csp_path)\n",
    "folder_list.sort()\n",
    "folder_list = folder_list[4:]\n",
    "for folder in folder_list:\n",
    "    folder_EEG = sorted(os.listdir(csp_path + folder+\"/EEG\"))\n",
    "    for i in range(len(folder_EEG)):\n",
    "        if folder_EEG[i][0] == '.':\n",
    "            continue\n",
    "        if pd.read_csv(csp_path + folder+\"/EEG/\"+folder_EEG[i], header = None).values.all() == 0:\n",
    "            zero_EEG.append(folder_EEG[i])\n",
    "            print(folder_EEG[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fv_te_imagined',\n",
       " 'fv_te_spoken',\n",
       " 'fv_tr_imagined',\n",
       " 'fv_tr_spoken',\n",
       " 'fv_val_imagined',\n",
       " 'fv_val_spoken']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "fv_data = os.listdir(csp_path)\n",
    "fv_data.sort()\n",
    "fv_data = fv_data[4:]\n",
    "fv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImaginedEEG_vec test number is: 118\n",
      "SpokenEEG_vec test number is: 117\n",
      "ImaginedEEG_vec train number is: 234\n",
      "SpokenEEG_vec train number is: 234\n",
      "ImaginedEEG_vec val number is: 117\n",
      "SpokenEEG_vec val number is: 117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_with_incremented_name(full_file_name, target_dir):\n",
    "    # Split the file name and extension\n",
    "    base_name = os.path.basename(full_file_name)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "\n",
    "    # Set the target path for copying\n",
    "    target_file = os.path.join(target_dir, base_name)\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    counter = 1\n",
    "    while os.path.exists(target_file):\n",
    "        # Add a number to the file name if it exists\n",
    "        if counter <10:\n",
    "            new_name = f\"{name}(00{counter}){ext}\"\n",
    "        else:\n",
    "            new_name = f\"{name}(0{counter}){ext}\"\n",
    "        target_file = os.path.join(target_dir, new_name)\n",
    "        counter += 1\n",
    "\n",
    "    # Copy the file\n",
    "    shutil.copy(full_file_name, target_file)\n",
    "\n",
    "# Main code\n",
    "for i in range(len(fv_data)):\n",
    "    # Determine the data type (test, train, or validation)\n",
    "    if fv_data[i].find(\"te\") != -1:\n",
    "        data_type = \"test\"\n",
    "    elif fv_data[i].find(\"tr\") != -1:\n",
    "        data_type = \"train\"\n",
    "    elif fv_data[i].find(\"val\") != -1:\n",
    "        data_type = \"val\"\n",
    "        \n",
    "    # Determine the data task (imagined or spoken)\n",
    "    if fv_data[i].find(\"imagined\") != -1:\n",
    "        data_task = \"im\"\n",
    "    elif fv_data[i].find(\"spoken\") != -1:\n",
    "        data_task = \"sp\"\n",
    "   \n",
    "    # Define paths\n",
    "    path_CSP_EEG = csp_path + fv_data[i] + \"/EEG/\"\n",
    "    path_CSP_label = csp_path + fv_data[i] + \"/label/\"\n",
    "    path_mel = foundation_path + f\"Patients/preprocessed/{sub_number}/about_voice/{sub_number}_mel/\"\n",
    "    path_total = [path_CSP_EEG, path_CSP_label, path_mel]\n",
    "    \n",
    "    for pa in path_total:\n",
    "        # Source directory for copying\n",
    "        source_dir = pa\n",
    "        \n",
    "        # Define the target directory for EEG data\n",
    "        if pa.find(\"EEG\") != -1:\n",
    "            if data_task == \"im\":   \n",
    "                target_dir = foundation_path + f\"dataset/{sub_number}/\" + data_type + \"/ImaginedEEG_vec/\"\n",
    "            elif data_task == \"sp\":\n",
    "                target_dir = foundation_path + f\"dataset/{sub_number}/\" + data_type + \"/SpokenEEG_vec/\"\n",
    "                \n",
    "        # Define the target directory for label data\n",
    "        elif pa.find(\"label\") != -1:\n",
    "            if data_task == \"im\":   \n",
    "                target_dir = foundation_path + f\"dataset/{sub_number}/\" + data_type + \"/im_Y/\"\n",
    "            elif data_task == \"sp\":\n",
    "                target_dir = foundation_path + f\"dataset/{sub_number}/\" + data_type + \"/sp_Y/\"\n",
    "                \n",
    "        # Define the target directory for mel data\n",
    "        elif pa.find(\"mel\") != -1:\n",
    "            if data_task == \"im\":   \n",
    "                target_dir = foundation_path + f\"dataset/{sub_number}/\" + data_type + \"/im_Y_mel/\"\n",
    "            elif data_task == \"sp\":\n",
    "                target_dir = foundation_path + f\"dataset/{sub_number}/\" + data_type + \"/sp_Y_mel/\"\n",
    "        \n",
    "        # Iterate over all files in the source directory and copy them\n",
    "        for file_name in os.listdir(source_dir):\n",
    "            full_file_name = os.path.join(source_dir, file_name)\n",
    "            \n",
    "            # Check if it is a file and copy it\n",
    "            if os.path.isfile(full_file_name):\n",
    "                copy_with_incremented_name(full_file_name, target_dir)\n",
    "                if pa.find(\"mel\") != -1:\n",
    "                    # if 'ima_vec_num' in locals():\n",
    "                    #     session_num = ima_vec_num // 13\n",
    "                    # elif 'spo_vec_num' in locals():\n",
    "                    #     session_num = spo_vec_num//13\n",
    "                    # for i in range(session_num):\n",
    "                        # copy_with_incremented_name(full_file_name, target_dir)\n",
    "                # else:\n",
    "                \n",
    "                    \n",
    "                    # Track the number of files in the imagined EEG directory\n",
    "                    if pa.find(\"EEG\") != -1 and pa.find(\"imagined\") != -1:\n",
    "                        ima_vec_num = len(os.listdir(pa))\n",
    "\n",
    "                    # Track the number of files in the spoken EEG directory\n",
    "                    elif pa.find(\"EEG\") != -1 and pa.find(\"spoken\") != -1:\n",
    "                        spo_vec_num = len(os.listdir(pa))\n",
    "                 \n",
    "        # Print the number of imagined EEG files\n",
    "        if pa.find(\"EEG\") != -1 and pa.find(\"imagined\") != -1:\n",
    "            ima_vec_num = len(os.listdir(pa))\n",
    "            print(f\"ImaginedEEG_vec {data_type} number is: {ima_vec_num}\")\n",
    "        \n",
    "        # Print the number of spoken EEG files\n",
    "        elif pa.find(\"EEG\") != -1 and pa.find(\"spoken\") != -1:\n",
    "            spo_vec_num = len(os.listdir(pa))\n",
    "            print(f\"SpokenEEG_vec {data_type} number is: {spo_vec_num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_EEG_len = len(zero_EEG)\n",
    "\n",
    "# Loop through the zero_EEG list\n",
    "for i in range(zero_EEG_len):   \n",
    "    # Construct the path to the CSP files\n",
    "    zero_csp_path = os.path.join(csp_path, zero_EEG[i][:-12])\n",
    "    zero_csv = os.path.join(zero_csp_path, zero_EEG[i])\n",
    "    \n",
    "    # Determine the data task: imagined or spoken\n",
    "    if zero_csv.find(\"imagined\") != -1:\n",
    "        data_ta = \"im\"\n",
    "        full_data_ta = \"ImaginedEEG_vec\"\n",
    "    elif zero_csv.find(\"spoken\") != -1:\n",
    "        data_ta = \"sp\"\n",
    "        full_data_ta = \"SpokenEEG_vec\"\n",
    "        \n",
    "    # Determine the data type: train, val, or test\n",
    "    if zero_csv.find(\"tr\") != -1:\n",
    "        data_ty = \"train\"\n",
    "    elif zero_csv.find(\"val\") != -1:\n",
    "        data_ty = \"val\"\n",
    "    elif zero_csv.find(\"te\") != -1:\n",
    "        data_ty = \"test\"\n",
    "        \n",
    "    # Define paths for mel, label, and EEG data\n",
    "    mel_path = foundation_path + f\"dataset/{sub_number}/{data_ty}/\" + data_ta + \"_Y_mel/\"\n",
    "    label_path = foundation_path + f\"dataset/{sub_number}/{data_ty}/\" + data_ta + \"_Y/\" \n",
    "    EEG_path = foundation_path + f\"dataset/{sub_number}/{data_ty}/{full_data_ta}/\"\n",
    "       \n",
    "    # Extract label numbers from the file name\n",
    "    label_num = int(zero_csv[-11:-8])\n",
    "    label_num_num = int(zero_csv[-6:-4])   \n",
    "\n",
    "    # Remove the corresponding EEG file\n",
    "    os.remove(EEG_path + zero_EEG[i])\n",
    "    if data_ta == \"sp\":\n",
    "        if data_ty != \"val\":\n",
    "            # Iterate over the files in the mel directory\n",
    "            for com in os.listdir(mel_path):\n",
    "                try:\n",
    "                    # Check if the first label number matches\n",
    "                    if int(com[17:20]) == label_num:\n",
    "                        # Debug: check if label_num_num and file extension match\n",
    "                        \n",
    "                        # If the second label number matches, remove the file\n",
    "                        if int(com[21:24]) == label_num_num:\n",
    "                            os.remove(mel_path + com)\n",
    "                except:\n",
    "                    # If the label_num_num is 0 and the file extension is \"csv\", remove the file\n",
    "                    if label_num_num == 0 and com[21:] == \"csv\":\n",
    "                        os.remove(mel_path + com)\n",
    "\n",
    "            # Iterate over the files in the label directory\n",
    "            for com in os.listdir(label_path):\n",
    "                try:\n",
    "                    # Check if both label numbers match\n",
    "                    if int(com[13:16]) == label_num:\n",
    "                        if int(com[17:20]) == label_num_num:\n",
    "                            os.remove(label_path + com)\n",
    "                except:\n",
    "                    # Ignore errors (e.g., if the file name format is unexpected)\n",
    "                    pass\n",
    "        else:\n",
    "            # Iterate over the files in the mel directory\n",
    "            for com in os.listdir(mel_path):\n",
    "                try:\n",
    "                    # Check if the first label number matches\n",
    "                    if int(com[17:20]) == label_num:\n",
    "                        # Debug: check if label_num_num and file extension match\n",
    "                        \n",
    "                        # If the second label number matches, remove the file\n",
    "                        if int(com[21:24]) == label_num_num:\n",
    "                            os.remove(mel_path + com)\n",
    "                except:\n",
    "                    # If the label_num_num is 0 and the file extension is \"csv\", remove the file\n",
    "                    if label_num_num == 0 and com[21:] == \"csv\":\n",
    "                        os.remove(mel_path + com)\n",
    "\n",
    "            # Iterate over the files in the label directory\n",
    "            for com in os.listdir(label_path):\n",
    "                try:\n",
    "                    # Check if both label numbers match\n",
    "                    if int(com[14:17]) == label_num:\n",
    "                        if int(com[18:21]) == label_num_num:\n",
    "                            os.remove(label_path + com)\n",
    "                except:\n",
    "                    # Ignore errors (e.g., if the file name format is unexpected)\n",
    "                    pass\n",
    "                   \n",
    "    if data_ta == \"im\":\n",
    "        if data_ty != \"val\":\n",
    "            # Iterate over the files in the mel directory\n",
    "            for com in os.listdir(mel_path):\n",
    "                try:\n",
    "                    # Check if the first label number matches\n",
    "                    if int(com[17:20]) == label_num:\n",
    "                        # Debug: check if label_num_num and file extension match\n",
    "                        \n",
    "                        # If the second label number matches, remove the file\n",
    "                        if int(com[21:24]) == label_num_num:\n",
    "                            os.remove(mel_path + com)\n",
    "                except:\n",
    "                    # If the label_num_num is 0 and the file extension is \"csv\", remove the file\n",
    "                    if label_num_num == 0 and com[21:] == \"csv\":\n",
    "                        os.remove(mel_path + com)\n",
    "\n",
    "            # Iterate over the files in the label directory\n",
    "            for com in os.listdir(label_path):\n",
    "                try:\n",
    "                    # Check if both label numbers match\n",
    "                    if int(com[15:18]) == label_num:\n",
    "                        if int(com[19:22]) == label_num_num:\n",
    "                            os.remove(label_path + com)\n",
    "                except:\n",
    "                    # Ignore errors (e.g., if the file name format is unexpected)\n",
    "                    pass     \n",
    "        else:\n",
    "            # Iterate over the files in the mel directory\n",
    "            for com in os.listdir(mel_path):\n",
    "                try:\n",
    "                    # Check if the first label number matches\n",
    "                    if int(com[17:20]) == label_num:\n",
    "                        # Debug: check if label_num_num and file extension match\n",
    "                        \n",
    "                        # If the second label number matches, remove the file\n",
    "                        if int(com[21:24]) == label_num_num:\n",
    "                            os.remove(mel_path + com)\n",
    "                except:\n",
    "                    # If the label_num_num is 0 and the file extension is \"csv\", remove the file\n",
    "                    if label_num_num == 0 and com[21:] == \"csv\":\n",
    "                        os.remove(mel_path + com)\n",
    "\n",
    "            # Iterate over the files in the label directory\n",
    "            for com in os.listdir(label_path):\n",
    "                try:\n",
    "                    # Check if both label numbers match\n",
    "                    if int(com[16:19]) == label_num:\n",
    "                        if int(com[20:23]) == label_num_num:\n",
    "                            os.remove(label_path + com)\n",
    "                except:\n",
    "                    # Ignore errors (e.g., if the file name format is unexpected)\n",
    "                    pass                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zero_EEG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
